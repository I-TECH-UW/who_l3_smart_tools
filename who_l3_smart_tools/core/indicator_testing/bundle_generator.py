from datetime import datetime, timedelta
import os
import random
import json
from re import sub
import re

import pandas as pd
from who_l3_smart_tools.core.indicator_testing.generator_functions import *
from fhir.resources.bundle import Bundle


# This class takes a data file generated by the DataGenerator
# class and uses the variable values in placeholders to generate
# FHIR resources that represent a patient or test phenotype.
#
# To properly generalize the logic, this class holds a number of different mappings
# that map a feature to a generator function. This way, the class can dynamically
# generate the appropriate FHIR resource based on the feature. However, this code needs
# to be updated for each specific indicator, and for long-term maintainability, it would
# need to be better-defined in the L2 artifacts to allow for easier translation.
class BundleGenerator:
    feature_list = {}
    denominator_sum = 0
    numerator_sum = 0

    def __init__(
        self,
        data_file_path,
        output_directory,
        reporting_period_start=None,
        reporting_period_end=None,
    ):
        self.data_file_path = data_file_path
        self.all_feature_keys = self.get_all_feature_keys()
        self.fhir_generator = FhirGenerator(self.all_feature_keys)
        self.pd_data = pd.read_excel(data_file_path, sheet_name=None)

        # If reporting_period_start is not provided or invalid format, set a year ago
        if reporting_period_start is None or not datetime.fromisoformat(
            reporting_period_start
        ):
            self.reporting_period_start = (
                datetime.now() - timedelta(days=365)
            ).isoformat()
        else:
            self.reporting_period_start = reporting_period_start

        # If reporting_period_end is not provided or invalid format, set a year from start
        if reporting_period_end is None or not datetime.fromisoformat(
            reporting_period_end
        ):
            self.reporting_period_end = (
                datetime.fromisoformat(self.reporting_period_start)
                + timedelta(days=365)
            ).isoformat()
        else:
            self.reporting_period_end = reporting_period_end

        self.start_date = datetime.fromisoformat(self.reporting_period_start)
        self.end_date = datetime.fromisoformat(self.reporting_period_end)

        if not output_directory or not os.path.isdir(output_directory):
            output_directory = os.path.join(os.getcwd(), "output")

        self.parse_input_headers()

    # Mappings: Based on the input excel file column names, which are based on DAK
    # indicator definition logic.
    features = {
        "general": [
            "Patient",
            "Test",
        ],
        "disaggregation": [
            "Key population member type",
            "TB diagnosis result",
            "Presumptive TB",
            "Testing entry point",
        ],
        "HIV.IND.19": [
            "Self-testing",
            '(("Date HIV test results returned" in the reporting period)',
            '("HIV diagnosis date" in the reporting period))',
            "\"HIV test result\"='HIV-positive'",
        ],
        "HIV.IND.20": [
            '("HIV diagnosis date" in the reporting period))',
            '(("Date HIV test results returned" in the reporting period)',
            '"HIV test date" in the reporting period',
            "\"HIV test result\"='HIV-positive'",
        ],
        "HIV.IND.27": [
            "\"HIV treatment outcome\" IN 'Lost to follow up'",
            "\"HIV status\"='HIV-positive'",
            "\"HIV treatment outcome\" IN 'Death (documented)'",
            '"On ART"=True at reporting period end date',
            "\"HIV treatment outcome\" IN 'Transferred out'",
        ],
    }

    def get_all_feature_keys(self):
        all_keys = []
        for feature_list in self.features.values():
            all_keys.extend(feature_list)
        # Ensure unique keys
        if len(all_keys) != len(set(all_keys)):
            print(
                "Duplicate keys found in features dictionary - ensure definitions match across indicators."
            )
        return all_keys

    def parse_input_headers(self):
        # Consolidate features that start with the pattern
        # "<resource>.<attribute>" into a single key for
        # generator function lookup
        resource_pattern = r"^(?P<resource>\w+)\.(?P<attribute>\w+)$"

        # For each sheet in the data file, parse the headers into a
        # feature list that can be used to generate FHIR resources
        for sheet_name in self.pd_data.keys():
            if sheet_name.strip() not in self.features.keys():
                print(
                    f"Sheet '{sheet_name}' not processed - missing feature list entry!"
                )
                continue

            sheet_fl = []
            sheet_df = self.excel_data[sheet_name]

            for key in sheet_df.columns:
                resource_match = re.match(resource_pattern, key)
                if resource_match:
                    resource_key = f"{resource_match.group('resource')}"

                    if (
                        resource_key in self.all_feature_keys
                        and resource_key not in sheet_fl
                    ):
                        sheet_fl.append(resource_key)
                elif key.strip() == "Numerator" or key.strip() == "Denominator":
                    # Skip
                    pass
                elif key in self.all_feature_keys and key not in sheet_fl:
                    sheet_fl.append(key)
                else:
                    print(f"Key '{key}' not processed!")
            self.feature_list[sheet_name] = sheet_fl

    # Generator Fuctions
    # See generator_functions.py

    # Main Functions
    def generate_all_data(self):
        # Generate data for each sheet
        for sheet_name in self.pd_data.keys():
            for row in self.pd_data[sheet_name].iterrows():
                self.generate_row_bundle(row)

    def generate_row_bundle(self, row):
        # Generate a new FHIR bundle for each row in the data file

        # Initialize the list of resources to be included in the bundle
        bundle_resources = []

        return bundle

    # This method reads in a row from a data value file and generates a FHIR bundle
    # that encodes the incoming patient or test phenotype using FHIR resources.
    def generate_output_bundle(self, row):
        # Input: dictionary with relevant keys from the Excel row data
        # Generate Patient resource
        patient_resource = generate_patient_resource(row)
        bundle_resources.append(patient_resource)

        # Generate Observation for Key Population Status
        observation_resource = generate_observation_resource(row)
        bundle_resources.append(observation_resource)

        # If HIV_Positive, add Condition resource
        if row["HIV_Positive"]:
            condition_resource = generate_condition_resource(row, start_date, end_date)
            bundle_resources.append(condition_resource)
        else:
            # Randomly decide to either do nothing or add a Condition resource outside the period
            if random.choice([True, False]):
                condition_resource = generate_condition_resource(
                    row, start_date - timedelta(days=10), end_date - timedelta(days=1)
                )
                bundle_resources.append(condition_resource)

        # If HIV_Treatment, add MedicationStatement resource
        if row["HIV_Treatment"]:
            medication_resource = generate_medication_statement_resource(
                row, start_date, end_date
            )
            bundle_resources.append(medication_resource)
        else:
            # Randomly decide to either do nothing or add a MedicationStatement resource outside the period
            if random.choice([True, False]):
                medication_resource = generate_medication_statement_resource(
                    row, start_date - timedelta(days=10), end_date - timedelta(days=1)
                )
                bundle_resources.append(medication_resource)

        # If Deceased, add deceased information to Patient resource
        if row["Deceased"]:
            patient_resource = add_deceased_information(patient_resource, end_date)
        else:
            # Randomly decide to either do nothing or add deceased information after the period
            if random.choice([True, False]):
                patient_resource = add_future_deceased_information(
                    patient_resource, end_date
                )

        # If Stopped_ART, add an EpisodeOfCare resource with status finished
        if row["Stopped_ART"]:
            episode_of_care_resource = (
                generate_episode_of_care_finished_before_measurement(row, end_date)
            )
            bundle_resources.append(episode_of_care_resource)
        else:
            # Randomly decide to either do nothing or add an EpisodeOfCare resource with status active
            if random.choice([True, False]):
                episode_of_care_resource = (
                    generate_episode_of_care_finished_after_measurement(row, end_date)
                )
                bundle_resources.append(episode_of_care_resource)

        # Compile all resources into a bundle
        bundle = create_bundle(bundle_resources)

        return bundle

    def create_bundle(self, resources):

        return create_transaction_bundle(resources)

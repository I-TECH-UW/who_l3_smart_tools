from datetime import datetime, timedelta, timezone
import os
import random
import json
from re import sub
import re

import pandas as pd
from who_l3_smart_tools.core.indicator_testing.generator_functions import *
from fhir.resources.bundle import Bundle


# This class takes a data file generated by the DataGenerator
# class and uses the variable values in placeholders to generate
# FHIR resources that represent a patient or test phenotype.
#
# To properly generalize the logic, this class holds a number of different mappings
# that map a feature to a generator function. This way, the class can dynamically
# generate the appropriate FHIR resource based on the feature. However, this code needs
# to be updated for each specific indicator, and for long-term maintainability, it would
# need to be better-defined in the L2 artifacts to allow for easier translation.
class BundleGenerator:
    feature_list = {}
    denominator_sum = 0
    numerator_sum = 0

    def __init__(
        self,
        data_file_path,
        output_directory,
        reporting_period_start=None,
        reporting_period_end=None,
    ):
        self.data_file_path = data_file_path
        self.all_feature_keys = self.get_all_feature_keys()
        self.pd_data = pd.read_excel(data_file_path, sheet_name=None)

        # If reporting_period_start is not provided or invalid format, set a year ago
        if (
            reporting_period_start is None
            or type(reporting_period_start) is not str
            or not datetime.fromisoformat(reporting_period_start)
        ):
            self.reporting_period_start = (
                datetime.now(timezone.utc) - timedelta(days=365)
            ).isoformat()
        else:
            self.reporting_period_start = reporting_period_start

        # If reporting_period_end is not provided or invalid format, set a year from start
        if (
            reporting_period_end is None
            or type(reporting_period_end) is not str
            or not datetime.fromisoformat(reporting_period_end)
        ):
            self.reporting_period_end = (
                datetime.fromisoformat(self.reporting_period_start)
                + timedelta(days=365)
            ).isoformat()
        else:
            self.reporting_period_end = reporting_period_end

        self.start_date = datetime.fromisoformat(self.reporting_period_start)
        self.end_date = datetime.fromisoformat(self.reporting_period_end)

        self.fhir_generator = FhirGenerator(
            self.all_feature_keys, self.start_date, self.end_date
        )

        if not output_directory or not os.path.isdir(output_directory):
            output_directory = os.path.join(os.getcwd(), "output")

        self.parse_input_headers()

    # Mappings: Based on the input excel file column names, which are based on DAK
    # indicator definition logic.
    features = {
        "general": [
            "Patient",
            "Test",
        ],
        "disaggregation": [
            "Key population member type",
            "TB diagnosis result",
            "Presumptive TB",
            "Testing entry point",
        ],
        "HIV.IND.19": [
            "Self-testing",
            '(("Date HIV test results returned" in the reporting period)',
            '("HIV diagnosis date" in the reporting period))',
            "\"HIV test result\"='HIV-positive'",
        ],
        "HIV.IND.20": [
            '("HIV diagnosis date" in the reporting period))',
            '(("Date HIV test results returned" in the reporting period)',
            '"HIV test date" in the reporting period',
            "\"HIV test result\"='HIV-positive'",
        ],
        "HIV.IND.27": [
            "\"HIV treatment outcome\" IN 'Lost to follow up'",
            "\"HIV status\"='HIV-positive'",
            "\"HIV treatment outcome\" IN 'Death (documented)'",
            '"On ART"=True at reporting period end date',
            "\"HIV treatment outcome\" IN 'Transferred out'",
        ],
    }

    def get_all_feature_keys(self):
        all_keys = []
        for feature_list in self.features.values():
            all_keys.extend(feature_list)
        # Ensure unique keys
        if len(all_keys) != len(set(all_keys)):
            print(
                "Duplicate keys found in features dictionary - ensure definitions match across indicators."
            )
        return all_keys

    def parse_input_headers(self):
        # Consolidate features that start with the pattern
        # "<resource>.<attribute>" into a single key for
        # generator function lookup
        resource_pattern = r"^(?P<resource>\w+)\.(?P<attribute>\w+)$"

        # For each sheet in the data file, parse the headers into a
        # feature list that can be used to generate FHIR resources
        for sheet_name in self.pd_data.keys():
            if sheet_name.strip() not in self.features.keys():
                print(
                    f"Sheet '{sheet_name}' not processed - missing feature list entry!"
                )
                continue

            sheet_fl = []
            sheet_df = self.pd_data[sheet_name]

            for key in sheet_df.columns:
                resource_match = re.match(resource_pattern, key)
                if resource_match:
                    resource_key = f"{resource_match.group('resource')}"

                    if (
                        resource_key in self.all_feature_keys
                        and resource_key not in sheet_fl
                    ):
                        sheet_fl.append(resource_key)
                elif key.strip() == "Numerator" or key.strip() == "Denominator":
                    # Skip
                    pass
                elif key in self.all_feature_keys and key not in sheet_fl:
                    sheet_fl.append(key)
                else:
                    print(f"Key '{key}' not processed!")
            self.feature_list[sheet_name] = sheet_fl

    # Generator Functions
    # See generator_functions.py

    # Main Functions
    def generate_all_data(self):
        all_data = {}
        # Generate data for each sheet
        for sheet_name in self.pd_data.keys():
            all_data[sheet_name] = []
            sheet_fl = self.feature_list[sheet_name]

            # Generate bundle for each row
            for index, row in self.pd_data[sheet_name].iterrows():
                bundle = self.generate_row_bundle(row, sheet_fl)
                all_data[sheet_name].append(bundle)
        return all_data

    def generate_row_bundle(self, row, feature_list):
        # Generate a new FHIR bundle for the given row and feature list

        # Initialize the list of resources to be included in the bundle
        bundle = Bundle.construct()

        for feature in feature_list:
            # Generate the FHIR resource for the given feature
            bundle = self.fhir_generator.generate_for(feature, row, bundle)

        return bundle

    def create_bundle(self, resources):

        return create_transaction_bundle(resources)

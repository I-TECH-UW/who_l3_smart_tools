from datetime import datetime, timedelta, timezone
import os
import json
import re

import pandas as pd
from who_l3_smart_tools.core.indicator_testing.v1.generator_functions import *
from fhir.resources.bundle import Bundle
from fhir.resources.measurereport import MeasureReport
from fhir.resources.meta import Meta


# This class takes a data file generated by the DataGenerator
# class and uses the variable values in placeholders to generate
# FHIR resources that represent a patient or test phenotype.
#
# To properly generalize the logic, this class holds a number of different mappings
# that map a feature to a generator function. This way, the class can dynamically
# generate the appropriate FHIR resource based on the feature. However, this code needs
# to be updated for each specific indicator, and for long-term maintainability, it would
# need to be better-defined in the L2 artifacts to allow for easier translation.
class BundleGenerator:
    feature_list = {}
    all_data = None

    def __init__(
        self,
        data_file_path,
        output_directory,
        reporting_period_start=None,
        reporting_period_end=None,
    ):
        self.data_file_path = data_file_path
        self.all_feature_keys = self.get_all_feature_keys()
        self.pd_data = pd.read_excel(data_file_path, sheet_name=None)

        # If reporting_period_start is not provided or invalid format, set a year ago
        if (
            reporting_period_start is None
            or type(reporting_period_start) is not str
            or not datetime.fromisoformat(reporting_period_start)
        ):
            self.reporting_period_start = (
                datetime.now(timezone.utc) - timedelta(days=365)
            ).isoformat()
        else:
            self.reporting_period_start = reporting_period_start

        # If reporting_period_end is not provided or invalid format, set a year from start
        if (
            reporting_period_end is None
            or type(reporting_period_end) is not str
            or not datetime.fromisoformat(reporting_period_end)
        ):
            self.reporting_period_end = (
                datetime.fromisoformat(self.reporting_period_start)
                + timedelta(days=365)
            ).isoformat()
        else:
            self.reporting_period_end = reporting_period_end

        self.start_date = datetime.fromisoformat(self.reporting_period_start)
        self.end_date = datetime.fromisoformat(self.reporting_period_end)

        self.fhir_generator = FhirGenerator(
            self.all_feature_keys, self.start_date, self.end_date
        )

        if not output_directory or not os.path.isdir(output_directory):
            output_directory = os.path.join(os.getcwd(), "output")

        self.output_directory = output_directory

        self.parse_input_headers()

    # Getters
    def get_all_data(self):
        return self.all_data

    # Mappings: Based on the input excel file column names, which are based on DAK
    # indicator definition logic.
    features = {
        "general": [
            "Patient",
            "Test",
        ],
        "disaggregation": [
            "Key population member type",
            "TB diagnosis result",
            "Presumptive TB",
            "Testing entry point",
        ],
        "HIV.IND.19": [
            "Self-testing",
            '(("Date HIV test results returned" in the reporting period)',
            '("HIV diagnosis date" in the reporting period))',
            "\"HIV test result\"='HIV-positive'",
        ],
        "HIV.IND.20": [
            '("HIV diagnosis date" in the reporting period))',
            '(("Date HIV test results returned" in the reporting period)',
            '"HIV test date" in the reporting period',
            "\"HIV test result\"='HIV-positive'",
        ],
        "HIV.IND.27": [
            "\"HIV treatment outcome\" IN 'Lost to follow up'",
            "\"HIV status\"='HIV-positive'",
            "\"HIV treatment outcome\" IN 'Death (documented)'",
            '"On ART"=True at reporting period end date',
            "\"HIV treatment outcome\" IN 'Transferred out'",
        ],
    }

    def get_all_feature_keys(self):
        all_keys = []
        for feature_list in self.features.values():
            all_keys.extend(feature_list)
        # Ensure unique keys
        if len(all_keys) != len(set(all_keys)):
            print(
                "Duplicate keys found in features dictionary - ensure definitions match across indicators."
            )
        return all_keys

    def parse_input_headers(self):
        # Consolidate features that start with the pattern
        # "<resource>.<attribute>" into a single key for
        # generator function lookup
        resource_pattern = r"^(?P<resource>\w+)\.(?P<attribute>\w+)$"

        # For each sheet in the data file, parse the headers into a
        # feature list that can be used to generate FHIR resources
        for sheet_name in self.pd_data.keys():
            if sheet_name.strip() not in self.features.keys():
                print(
                    f"Sheet '{sheet_name}' not processed - missing feature list entry!"
                )
                continue

            sheet_fl = []
            sheet_df = self.pd_data[sheet_name]

            for key in sheet_df.columns:
                resource_match = re.match(resource_pattern, key)
                if resource_match:
                    resource_key = f"{resource_match.group('resource')}"

                    if (
                        resource_key in self.all_feature_keys
                        and resource_key not in sheet_fl
                    ):
                        sheet_fl.append(resource_key)
                elif key.strip() == "Numerator" or key.strip() == "Denominator":
                    # Skip
                    pass
                elif key in self.all_feature_keys and key not in sheet_fl:
                    sheet_fl.append(key)
                else:
                    print(f"Key '{key}' not processed!")
            self.feature_list[sheet_name] = sheet_fl

    # For Generator Functions: See generator_functions.py

    # Main Functions
    def generate_all_data(self):
        all_data = {}
        # Generate data for each sheet
        for sheet_name in self.pd_data.keys():
            numerator_sum = 0
            denominator_sum = 0

            all_data[sheet_name] = {"bundles": [], "MeasureReport": None}
            sheet_fl = self.feature_list[sheet_name]

            # Generate bundle for each row
            for index, row in self.pd_data[sheet_name].iterrows():
                row_numerator = row["Numerator"]
                row_denominator = row["Denominator"]

                numerator_sum += row_numerator if row_numerator else 0
                denominator_sum += row_denominator if row_denominator else 0

                bundle = self.generate_row_bundle(row, sheet_fl)

                all_data[sheet_name]["bundles"].append(bundle)

            # Generate MeasurementReport for the sheet
            all_data[sheet_name]["MeasureReport"] = (
                self.generate_example_measure_report(
                    len(self.pd_data[sheet_name]), numerator_sum, denominator_sum
                )
            )

        self.all_data = all_data

        return all_data

    def datetime_handler(self, obj):
        if isinstance(obj, datetime):
            return obj.__str__()

    def save_to_file(self):
        output_directory = self.output_directory
        # Save the generated FHIR resources to a file
        if not output_directory or not os.path.isdir(output_directory):
            output_directory = os.path.join(os.getcwd(), "output")

        for sheet_name, data in self.all_data.items():
            sheet_output_directory = os.path.join(output_directory, sheet_name)
            if not os.path.isdir(sheet_output_directory):
                os.makedirs(sheet_output_directory)

            for index, bundle in enumerate(data["bundles"]):
                file_name = f"{sheet_name}_bundle_{index}.json"
                file_path = os.path.join(sheet_output_directory, file_name)

                with open(file_path, "w") as f:
                    f.write(
                        json.dumps(
                            bundle.dict(), indent=4, default=self.datetime_handler
                        )
                    )

            file_name = f"{sheet_name}_measure_report.json"
            file_path = os.path.join(sheet_output_directory, file_name)

            with open(file_path, "w") as f:
                f.write(
                    json.dumps(
                        data["MeasureReport"].dict(),
                        indent=4,
                        default=self.datetime_handler,
                    )
                )

    def generate_example_measure_report(self, num_rows, numerator_sum, denominator_sum):
        # Generate an example MeasurementReport resource

        # Initialize the MeasurementReport resource
        measurement_report = MeasureReport.parse_obj(
            {
                "resourceType": "MeasureReport",
                "status": "final",
                "type": "summary",
                "date": datetime.now(timezone.utc).isoformat(),
                "period": {
                    "start": self.reporting_period_start,
                    "end": self.reporting_period_end,
                },
            }
        )

        measurement_report.group = []
        measurement_report.group.append(
            {
                "population": [
                    {
                        "code": {"coding": [{"code": "initial-population"}]},
                        "count": num_rows,
                    },
                    {
                        "code": {"coding": [{"code": "numerator"}]},
                        "count": numerator_sum,
                    },
                    {
                        "code": {"coding": [{"code": "denominator"}]},
                        "count": denominator_sum,
                    },
                ]
            }
        )
        return measurement_report

    def generate_row_bundle(self, row, feature_list):
        # Generate a new FHIR bundle for the given row and feature list

        # Initialize the list of resources to be included in the bundle
        bundle = Bundle.parse_obj(
            {"resourceType": "Bundle", "type": "transaction", "entry": []}
        )

        # Add metadata for patient phenotype used to generate this bundle
        bundle.meta = Meta.parse_obj(
            {
                "extension": [
                    {
                        "url": "http://example.org/fhir/StructureDefinition/phenotype-pattern",
                        "extension": [],
                    },
                    {
                        "url": "http://example.org/fhir/StructureDefinition/numerator",
                        "valueInteger": row["Numerator"],
                    },
                    {
                        "url": "http://example.org/fhir/StructureDefinition/denominator",
                        "valueInteger": row["Denominator"],
                    },
                ]
            }
        )
        # Add phenotype values for each feature
        for feature in feature_list:
            if feature not in ["Patient", "Test"]:
                bundle.meta.extension[0].extension.append(
                    {
                        "url": f"http://example.org/fhir/StructureDefinition/{snake_case(feature)}",
                        "valueBoolean": bool(row[feature]),
                    }
                )

        for feature in feature_list:
            # Generate the FHIR resource for the given feature
            bundle = self.fhir_generator.generate_for(feature, row, bundle)

        return bundle

    def create_bundle(self, resources):

        return create_transaction_bundle(resources)
